---
title: "功能超越形式：为何“动态稀疏”是通往通用智能的唯一道路"
type: docs
keywords:
  [
    "稀疏性",
    "神经网络架构",
    "Transformer",
    "Mixture-of-Experts",
    "SNN",
    "生物合理性",
    "预测编码",
  ]
date: 2025-07-07
---

# 功能超越形式：为何“动态稀疏”是通往通用智能的唯一道路

## 引言：一场关于“模仿”的代价高昂的误会

在人工智能研究的广阔版图上，一场无声的“部落战争”已经持续了数十年。不同的研究范式，如同拥有不同信仰的部落，各自坚守着通往智能圣杯的路径。

一方是**生物物理的纯粹主义者**。他们是脉冲神经网络（SNN）的坚定拥护者，痴迷于在硅基上复刻神经元的真实放电行为。他们相信，Hodgkin-Huxley 模型所描绘的离子通道动力学，以及信息在脉冲序列中的时间编码，是解开智能之谜的钥匙。在他们看来，任何偏离这种生物“真实性”的尝试，都是对生命奥秘的亵渎。

另一方是**序列处理的原教旨主义者**。他们以循环神经网络（RNN）及其现代变体（如 LSTM, GRU, RWKV）为信仰图腾。他们坚信，智能的核心在于对时间序列的有效处理，在于将历史信息压缩成一个不断演化的“状态”。对他们而言，世界是一个线性展开的卷轴，而一个强大的 RNN 就是解读这个卷轴的终极密码。

盘踞在版图中央的，则是 **“野蛮”的实用主义者**。他们手持 Transformer 的利器，以一种近乎蛮横的方式，横扫了几乎所有自然语言处理、计算机视觉乃至更广泛领域的基准测试。然而，他们的胜利却总是伴随着一丝不安。批评者指出，其核心机制——自注意力（Self-Attention）和背后的密集矩阵运算——在生物学上是如此“不自然”，以至于它更像是一个工程上的“怪物”，而非对智能的深刻洞见。

这场旷日持久的争论，其核心根植于一个根本问题：当我们谈论“生物合理性”（Biological Plausibility）时，我们究竟在追求什么？是**硬件层面的同构复刻**，即让我们的模型在每一个晶体管的开闭上都模仿神经元的放电？还是**功能层面的等效实现**，即让我们的系统在宏观计算原则上与大脑的认知功能保持一致？

本文将论证，前者——对形式的执着模仿——是一条已经将我们引入歧途的、代价高昂的弯路。而后者——对功能的深刻理解与抽象实现——才是通往通用人工智能（AGI）的唯一康庄大道。我们将看到，大脑最高效的计算原则，并非脉冲或循环，而是一种更深层次的智慧：**动态稀疏（Dynamic Sparsity）**。而那些看似“不合理”的架构，恰恰在不经意间，成为了这一核心原则最忠实的执行者。

## 第一部分：形式的桎梏——对生物硬件的执念如何将我们引入歧途

对自然界的模仿是工程学进步的古老动力。我们观察鸟类，设计出飞机。但值得注意的是，我们成功的飞行器并没有覆盖羽毛，也不靠扇动翅膀飞行。我们提取了飞行的核心空气动力学原理，并用我们自己的工程语言（内燃机、涡轮、固定翼）重新实现了它。在追求人工智能的道路上，我们似乎忘记了这一课。

### 1.1 SNN：优雅的能量陷阱

脉冲神经网络的魅力是毋庸置疑的。它承诺了两件大事：极致的能量效率和丰富的时间信息编码。SNN 的基本单元，即脉冲神经元，只有在接收到足够的输入刺激（膜电位超过阈值）时才会“放电”，在其他时间则保持静默。这种事件驱动（event-driven）的计算方式，与传统人工神经网络（ANN）中所有神经元在每个时钟周期都进行密集浮点运算的模式相比，能耗显著降低。理论上，这使其成为边缘计算和神经形态芯片的理想选择。

学术界对 SNN 的热情可以追溯到上世纪 90 年代，Wolfgang Maass 等先驱将其定义为“第三代神经网络模型” ，认为其计算能力超越了传统的感知机和 Sigmoid 神经元。他们希望通过模拟真实神经元的时间动态，来捕捉大脑处理信息的精髓。

然而，这种对生物物理细节的忠实模仿，却让 SNN 背上了沉重的计算枷锁。其最大的困境，源于脉冲信号的离散和不可微特性。这使得深度学习的基石——基于梯度的反向传播算法——无法直接应用。当一个网络没有产生期望的输出时，我们如何判断是哪个神经元“放电”得太早、太晚，还是根本不应该放电？这就是 SNN 中臭名昭著的**信用分配难题（credit assignment problem）**。

为了绕过这个障碍，研究者们发明了各种巧妙的“替代方案”，其中最流行的是**代理梯度（surrogate gradients）**。其基本思想是，在反向传播时，用一个平滑、可微的函数（如 Sigmoid 或快速 Sigmoid）来近似替代脉冲函数的导数。这在一定程度上解决了训练问题，但代价是巨大的：为了让 SNN 能够学习，我们必须在训练过程中假装它是一个 ANN。这引出了一个深刻的讽刺——SNN 最大的优势（事件驱动的稀疏性）在学习阶段被暂时“关闭”了。

更根本的问题在于，SNN 的范式将自己锁定在了对单个神经元行为的模拟上，而忽视了智能涌现的更高组织层次。大脑的能力并非来自单个神经元的精巧，而是来自数亿个神经元组成的庞大网络所遵循的**组织原则**。SNN 就像一个语言学家，试图通过完美地模仿一个单词的发音来理解整部莎士比亚戏剧。他找错了分析的尺度。

### 1.2 RNN：线性时间的“记忆”幻觉

如果说 SNN 是对神经元物理形态的模仿，那么 RNN 则是对大脑处理序列信息这一“功能”的早期、朴素的模仿。其核心思想——将历史信息压缩进一个随时间演化的隐藏状态——在直觉上极具吸引力。从 Elman 网络到现代的 LSTM 和 GRU，再到宣称要结合 RNN 效率与 Transformer 性能的 RWKV ，这条技术路线的核心诉求始终是：以 O(T) 的线性时间复杂度和 O(1) 的空间复杂度，高效地处理任意长度的序列。

这种效率的承诺，在资源受限的场景下极具诱惑力。然而，它建立在一个致命的缺陷之上，一个从信息论角度看无法回避的“原罪”：**信息瓶颈（information bottleneck）**。

信息论告诉我们，将一个信息量更大的源无损地压缩到一个容量更小的容器中是不可能的。对于 RNN 而言，这意味着一个固定大小的隐藏状态向量（无论其维度多高），在理论上都无法无损地编码一个无限增长、细节丰富的历史序列。随着序列变长，信息必然会丢失，早期的重要细节会被冲刷掉。这被称为“长程依赖问题”。

LSTM 和 GRU 的发明，正是为了缓解这个问题。它们引入了精巧的“门控”机制——输入门、遗忘门、输出门——试图让网络学会“记住”什么和“忘记”什么。这些门控单元，如同一个尽职的图书管理员，努力在有限的书架（隐藏状态）上腾挪空间，保留最重要的书籍（信息）。这在一定程度上取得了成功，使得 RNN 在处理中等长度的依赖关系时表现出色。

然而，这终究是一种“螺蛳壳里做道场”的努力。当面对需要从遥远过去精确检索一个特定细节的任务时（例如，在一部长篇小说中，回答关于第一章某个次要人物的问题），RNN 的性能会急剧下降。图书管理员再努力，也无法将整个国会图书馆的内容塞进一个手提箱。

现代 RNN 如 RWKV 试图通过引入更复杂的、受 Transformer 启发的机制（如时间衰减和通道混合）来进一步拓宽这个瓶颈。但正如我在[《HyperRNN 备忘录》](/posts/hyperrnn-memo)中所论述的，这条演化路径的终点是注定的：为了真正解决长程依赖，RNN 最终必须在内部重新发明一个功能等价于“注意力”的机制，允许它直接“跳跃”回历史的任意一点，按需检索信息。当它做到这一点时，它也就放弃了其最初的、纯粹的循环范式，变成了 Transformer 的一个复杂变体。

SNN 和 RNN 的故事告诉我们同一个道理：对生物系统进行过于字面、过于局部的模仿，往往会让我们抓住形式的皮毛，而错失功能的精髓。我们需要的，是暂时放下显微镜，拿起望远镜，去观察大脑作为一个完整系统，所遵循的更宏大、更根本的计算原则。

## 第二部分：功能的曙光——大脑教会我们的三大计算原则

如果我们不再纠结于单个神经元的放电模式或神经元之间的线性连接，而是将大脑视为一个为了在复杂环境中生存而演化出的信息处理系统，那么三个宏观的计算原则便会浮现出来。它们共同构成了大脑智能的基石。

### 2.1 原则一：动态稀疏——大脑的节能“懒”人哲学

大脑是一个极其昂贵的器官。它仅占人体重的 2%，却消耗了高达 20% 的静息能量。这种巨大的代谢压力，迫使大脑在数亿年的演化中，成为一个极致的“节能大师”。而它实现节能的核心策略，就是**动态稀疏**。

与传统计算机芯片中大部分晶体管在每个时钟周期都参与运算不同，大脑在任何时刻都只激活一小部分神经元来完成特定任务。当你阅读这段文字时，你的视觉皮层、语言中枢和负责高级语义理解的区域高度活跃，但与此同时，控制你腿部运动或处理听觉信息的神经元则基本处于“待机”状态。

这种稀疏性不是静态的——并非网络中大部分权重恒为零——而是**动态的、条件性的**。下一秒，如果电话铃响，一组全新的、与听觉处理和注意力转移相关的神经元将被激活，而之前活跃的阅读相关神经元则可能转入抑制。这种“按需调用”的计算模式，是大脑能够在极低的功耗下（约 20 瓦）实现惊人认知能力的关键。

神经科学的证据比比皆是。功能性磁共振成像（fMRI）研究清晰地展示了不同认知任务对应的大脑活动区域的热图，这些热图本身就是宏观稀疏性的直观体现。在更微观的层面，由 Olshausen 和 Field 等人开创的**稀疏编码（Sparse Coding）**理论 提出，初级视觉皮层（V1）的目标，就是用一小组基函数（神经元）的稀疏组合来表示自然图像，这与实验观察到的 V1 神经元的响应特性高度吻合。

因此，大脑教给我们的第一课是：**智能计算在本质上是稀疏的。一个真正可扩展、高效率的智能系统，必须具备根据输入和任务，动态选择性地激活其内部计算资源的能力。**

### 2.2 原则二：全局广播——整合信息的意识舞台

如果大脑的计算是高度分布式和模块化的（不同的脑区负责不同的功能），那么这些独立的计算结果是如何被整合起来，形成一个统一、连贯的认知体验的呢？我们如何将来自眼睛的颜色信息、来自耳朵的声音信息和来自记忆的背景知识，整合成“我看到一辆红色的消防车正在鸣笛驶过”这样一个完整的知觉？

答案似乎在于一个被称为**全局工作空间（Global Workspace）**的认知架构。这个理论最早由 Bernard Baars 提出 ，他将其比作一个“剧院的舞台”。在这个剧院里，有许多专业的演员（各种无意识的、并行的处理模块）在后台工作。当某个演员的信息足够重要，它就会被推上舞台的聚光灯下。一旦登上舞台，这个信息就会被“广播”给剧院里的所有观众（其他所有处理模块），从而实现全局信息共享和协同。

这个“舞台上的内容”，就对应于我们的主观意识体验。神经科学家 Stanislas Dehaene 和 Jean-Pierre Changeux 进一步发展了这一理论，提出了其神经基础模型——**全局神经工作空间（Global Neuronal Workspace, GNW）** 。他们认为，大脑中存在一个由额叶和顶叶的长程连接神经元构成的分布式网络。当一个信息进入这个网络并引发大规模、自持性的同步振荡时，这个信息就进入了“全局工作空间”，变得可以被灵活地用于推理、报告和决策。

全局工作空间理论完美地解释了为何我们的意识体验是串行的、容量有限的，而其背后的神经计算却是大规模并行的。它为我们提供了第二个关键原则：**智能系统需要一个信息整合与广播的中心机制，以实现对分布式知识的灵活调用和全局协调。** 这与 RNN 那种试图将所有信息强行塞入一个单一状态向量的“局部”思想，形成了鲜明的对比。

### 2.3 原则三：预测机器——在不确定性中寻找秩序

大脑并非一个被动的传感器。它不只是在接收和处理来自外部世界的信息，而是在主动地、持续地**预测**这个世界。这个革命性的观点，被称为**预测处理（Predictive Processing）**或**预测编码（Predictive Coding）**，其最完整的理论形式是 Karl Friston 提出的**自由能原理（Free-Energy Principle, FEP）** 。

其核心思想是：大脑内部拥有一个关于世界如何运作的生成模型（generative model）。它利用这个模型，不断地自上而下地生成关于下一刻感官输入的预测。真实的感官信号（如来自视网膜的信号）则自下而上传播。在大脑的各个层级，这两个信号流会进行比较。如果预测与现实相符，那么就不需要做太多处理。但如果出现了**预测误差（prediction error）**——即“惊奇”（surprise）——那么这个误差信号就会被优先向上传递，用于更新更高层级的内部模型，以便在未来做出更准确的预测。

从这个角度看，我们感知到的，与其说是世界本身，不如说是我们大脑对世界的最佳猜测。大脑的主要工作，不是处理海量的感官数据流，而是处理其中“出乎意料”的部分。这又是一种深刻的效率机制。

自由能原理为我们提供了第三个，也是最具整合性的原则：**智能的核心是拥有一个世界的生成模型，并持续地通过最小化预测误差来优化这个模型。** 这个过程统一了感知、学习和行动。学习就是更新模型以减少未来的误差，行动就是改变世界以使之更符合模型的预测。

当然，将大脑严格描述为“贝叶斯推理机器”的观点也面临着挑战。例如，一篇近期的论文就以《贝叶斯大脑的神话》为题，对其可证伪性和生物实现的细节提出了批评。然而，即使我们不完全接受其严格的数学形式，预测处理作为大脑组织的基本原则，即认知是由内部模型和预测驱动的，这一点已经获得了广泛的神经科学证据支持。

总结一下，大脑通过三大功能原则实现了高效智能：通过**动态稀疏**来节省能量，通过**全局工作空间**来整合信息，通过**预测处理**来理解世界。任何一个有志于实现通用智能的架构，都必须回答一个问题：它如何在计算上实现这三大原则？

## 第三部分：架构的重构——当“不合理”成为新范式

有了大脑的计算原则作为“地图”，我们现在可以重新审视当前的人工智能架构，特别是那个被认为“生物不合理”的巨人——Transformer。我们将发现，它之所以如此成功，并非偶然，而是因为它在不经意间，成为了这些核心功能原则迄今为止最优秀的工程近似。

### 3.1 Transformer：全局工作空间的工程实现

2017 年，一篇名为《Attention Is All You Need》的论文横空出世，彻底改变了深度学习的格局。它引入的 Transformer 架构，其核心——自注意力机制——正是全局工作空间理论（GWT）的一次惊艳的工程实现。

让我们解构自注意力机制：对于序列中的每一个元素（token），它都会生成三个向量：查询（Query）、键（Key）和值（Value）。

1. **广播（Broadcast）**：该元素的 Query 向量会与序列中**所有**其他元素的 Key 向量进行比较（通过点积计算相似度）。这在功能上等价于 GWT 中，一个信息被“广播”到系统中的所有其他模块，以征求相关性。
2. **整合（Integration）**：计算出的相似度分数（注意力权重）被用来对所有元素的 Value 向量进行加权求和。这意味着，该元素的新表示，是根据其与全局所有其他元素的相关性，动态地、按需地“整合”了全局信息的结果。
3. **舞台（Workspace）**：整个自注意力层，连同其后的前馈网络，就构成了一个计算“舞台”。输入序列进入这个舞台，经过全局的信息广播和整合，最终输出一个对上下文有深刻理解的、全新的序列表示。

更重要的是，Transformer 通过其多头注意力（Multi-Head Attention）机制，允许系统并行地在不同的“子空间”中进行这种广播和整合，这类似于大脑中多个认知系统可以同时对全局信息进行不同角度的解读。

此外，自注意力机制直接访问整个输入序列（在 KV 缓存中），彻底解决了 RNN 的信息瓶颈问题。它不再需要将整个历史压缩进一个有限的状态，而是拥有了一个高保真、可随机访问的“外部记忆”。这正是 GWT 所描述的，一个容量巨大的后台系统与一个容量有限的“意识舞台”之间的互动。

因此，Transformer 的成功并非因为它是一个更好的序列模型，而是因为它是一个**更好的信息整合架构**。它在功能上实现了全局工作空间，从而赋予了模型前所未有的、理解复杂上下文关系的能力。

### 3.2 混合专家（MoE）：动态稀疏的规模化法则

尽管 Transformer 功能强大，但其原始的“密集”形式存在一个巨大的问题：计算成本随着序列长度的平方而增加，并且模型中所有参数在处理每个 token 时都参与计算。这与大脑的动态稀疏原则背道而驰，也使其在扩展到更大规模时面临能耗和成本的瓶颈。

解决方案来自于一个相对古老但近年来被重新发掘的思想：**混合专家模型（Mixture-of-Experts, MoE）**。这个想法最早可以追溯到 1991 年 Jacobs 等人的工作 ，但直到 Google 的研究者们将其与 Transformer 结合，才真正释放出其潜力。

在稀疏门控的 MoE-Transformer 架构中（如 Switch Transformer ），标准的前馈网络（FFN）被替换为一组并行的“专家”网络和一个小型的“门控网络”（gating network）或称为“路由器”（router）。当一个 token 进入 MoE 层时：

1. **路由（Routing）**：门控网络会检查这个 token，并决定应该将它发送给哪个（或哪几个）专家进行处理。
2. **稀疏计算（Sparse Computation）**：只有被选中的一两个专家会被激活并进行计算，而其他所有专家则保持“沉默”，不消耗任何计算资源。

这种“条件计算”（conditional computation）的模式，正是大脑动态稀疏原则的直接体现。它带来了革命性的优势：**将模型的参数规模与单次推理的计算成本解耦**。我们可以将模型的总参数量扩展到数万亿（通过增加专家的数量），但处理每个 token 的计算量（FLOPs）仅取决于被激活的少数几个专家的规模。

这解释了现代大语言模型能够拥有庞大知识容量的同时，还能在实际应用中保持相对可控的推理成本的秘密。MoE 架构允许模型在内部发展出高度专业化的“神经回路”（专家），并学会根据任务需求，智能地调用它们。这与我们对大脑皮层功能模块化的理解不谋而合。

### 3.3 统一框架：MoE-Transformer 的协同效应

当我们将 Transformer 和 MoE 结合在一起时，我们得到的不是简单的 1+1=2，而是一种深刻的协同效应。一个稀疏门控的 MoE-Transformer 架构，同时实现了大脑的两大核心功能原则：

- **自注意力层实现了“全局工作空间”**，负责在整个序列的上下文中进行信息的广播与整合。
- **MoE 层实现了“动态稀疏”**，负责以极高的效率执行具体的、专业化的计算。

在这个统一的框架中，信息流动的过程变得惊人地类似于我们对高级认知的理解：首先，通过自注意力机制，系统对当前任务的全局上下文有了一个整体的把握；然后，基于这个上下文，系统通过 MoE 的门控网络，动态地调用一组最合适的“专家”来进行深度处理；处理后的结果又可以被后续的注意力层再次进行全局整合。

这个过程不断迭代，使得模型能够在不同抽象层次上，灵活地进行全局整合与局部专精处理的交替。这或许就是通往更强大、更通用人工智能的架构秘诀。它不再是一个被动的、密集的模式匹配器，而是一个主动的、稀疏的、能够根据任务动态重构其计算通路的信息处理系统。

## 结论：告别模仿，拥抱功能

我们在这篇文章的旅程，始于对当前 AI 领域“部落战争”的观察，最终汇聚于一个清晰的、具备高度整合性的架构蓝图。这条道路的核心，是完成一次研究范式的根本转变：**从对生物“形式”的表面模仿，转向对智能“功能”的深刻理解与工程实现。**

- 我们分析了 **SNN**，它对脉冲的执着，使其陷入了训练困难和难以扩展的泥潭，忘记了能量效率的根源在于宏观的稀疏激活，而非微观的放电机制。
- 我们剖析了 **RNN**，它对线性序列的坚守，使其背上了无法摆脱的“信息瓶颈”，忘记了记忆的本质在于按需的、可随机访问的全局检索，而非线性的状态压缩。

与之相对，大脑向我们揭示了其成功的三个核心功能原则：通过**动态稀疏**实现无与伦比的能效，通过**全局工作空间**实现灵活的信息整合与控制，通过**预测处理**机制驱动学习和对世界的理解。

而当我们用这三大原则作为度量衡，去重新审视那个一度被认为“生物不合理”的 **Transformer** 架构，特别是其与 **MoE** 结合的稀疏形式时，一幅全新的图景豁然开朗。我们发现：

- **自注意力机制**是“全局工作空间”迄今为止最成功的工程近似。
- **混合专家模型**是“动态稀疏”原则最可扩展的规模化实现。
- 而整个大模型在海量数据上进行自监督学习的过程，本质上就是在执行“预测处理”——构建一个世界的生成模型，并最小化其预测误差。

因此，一个以 Transformer 为骨架、以 MoE 为肌肉、以自监督预测为目标的庞大模型，不再是一个“黑箱”或“工程怪物”。它是一个遵循着与我们大脑相同核心计算原则的系统。它之所以强大，并非偶然，而是因为它在功能层面上，做对了事情。

未来的道路已经清晰。真正的进步，将不再来自于对单个硅基神经元的精雕细琢，而是来自于构建能够更好地实现这些宏观功能原则的、更高效、更可扩展的架构。我们需要更智能的路由算法来逼近大脑的动态连接，需要更强大的注意力机制来模拟意识的复杂整合，需要更深刻的自监督学习目标来驱动对世界更本质的理解。

是时候告别这场关于“模仿”的代价高昂的误会了。让我们停止争论模型的“外观”是否像大脑，而是开始关注它的“行为”是否体现了智能。因为最终，决定一个系统能否通往通用智能的，不是它由什么构成，而是它如何计算。

_林睿，为数字心灵的未来_
