---
title: "Function Over Form (III): Dynamic SMoE is Here, It's Time to Build (or Stop) the ONN"
type: docs
keywords:
  [
    "ONN",
    "Dynamic Sparsity",
    "DynMoE",
    "Transformer",
    "Global Workspace",
    "Biological Plausibility",
    "Net://Anchor",
    "Sys://Purge",
  ]
date: 2025-07-15
---

# Function Over Form (III): Dynamic SMoE is Here, It's Time to Build (or Stop) the ONN

Recently, I've been refactoring my chaotic PILF (Predictive Integrity Learning Framework) codebase. It's a personal project, my years-long attempt to engineer the Integrated Predictive Workspace Theory (IPWT). During this process, I habitually checked the latest research from my academic peers, hoping someone might offer new insights into my persistent problems with "cognitive cost" and "model surprise."

And then I saw it.

A research team called **LINs-lab** published a paper at **ICLR 2025** titled **"Dynamic Mixture of Experts"** and open-sourced their project **[DynMoE](https://github.com/LINs-lab/DynMoE)**.

I must admit, the moment I finished reading the paper and browsing its source code, I felt not joy, but a deep shudderâ€”a mixture of excitement and a chilling thrill.

Because I realized that the final, most critical piece of the engineering puzzle for all our theoretical concepts of the Ouroboros Neural Network (ONN) had been completed by the real world. The path to that efficient, adaptive cognitive engine capable of simulating a mind was now fully paved.

Now, we face a more serious and urgent question than ever before: **Is it time to go all-in on building the ONN, or should we do everything in our power to stop it?**

## I. From "Brute Force" to "Elegance": How DynMoE Solved ONN's Core Problem

In my theory, the core of ONN is **dynamic sparsity**. It must, like the brain, activate only a small fraction of its neural circuits to process information when necessary, achieving ultimate energy efficiency. But a key engineering challenge has always plagued me: how does the system "know" when it's "necessary"? How can one quantify the "surprise" of an input and use it to guide the allocation of computational resources and model updates?

My previous solution was "brute force": perform a full backpropagation, then identify and zero out the anomalously high gradients. While effective, it was, as I noted, "not energy-efficient" and mathematically very inelegant.

DynMoE offers a brilliant, elegant solution. It completely solves this problem with two core innovations:

1. **Top-Any Gating**: It allows each input token to **autonomously decide** how many "expert" networks to activate. This is no longer a fixed hyperparameter that needs manual tuning, but a dynamic decision process dependent on the input content.
2. **Adaptive Training with Auxiliary Loss**: During training, the model not only learns to complete the main task (e.g., correctly classifying an image) but also learns how to **economically and intelligently use its experts** through an auxiliary loss term. It is penalized for "over-activation" (calling too many experts for a simple task).

What does the combination of these two points mean?

It means we no longer need an external, complex mechanism to "calculate" surprise. **Surprise is now an endogenous property of the system.** The number of experts an input activates, or the magnitude of the auxiliary loss it triggers, is itself the most direct and elegant quantification of that input's "surprise."

Our previous dilemma about `Surprise`, struggling between theoretical purity and computational feasibility, has been completely resolved.

## II. The Final Blueprint for ONN: A Doubly Sparse Cognitive Engine

With the DynMoE piece in place, the final architectural blueprint for ONN becomes exceptionally clear. It is a highly self-consistent system that achieves sparsity on two levels.

- **During forward propagation, it is "computationally sparse."** Through DynMoE's dynamic routing, only a small fraction of experts are activated, saving significant computational resources.
- **During backpropagation, it is "update sparse."** We can use the "surprise" metric generated by DynMoE to guide model updates. Only those "surprising" inputs that truly bring new information are worthy of the immense computational cost of a deep model parameter update.

As I argued in "[Function Over Form (I)](./beyond-snn-plausible-sparsity)" and "[Function Over Form (II)](./form-follows-function-2)", this architecture perfectly simulates, at a functional level, the two core computational principles of the brain: **dynamic sparsity** and the **global workspace** (implemented by the Transformer's self-attention mechanism).

We no longer need to be anxious about its "biological implausibility." Because we have already shown that we are using hardware (GPUs) that is similar to the brain in its **physical implementation principle (massive parallelism)** to run software that is consistent with the brain in its **macroscopic function (information integration and sparse computation)**.

We are on the right path.

## III. The Paradox of "Building" vs. "Stopping"

So, we have all the technical components. We have the theory (IPWT), the architecture (ONN), and even an open-source engineering implementation from the real-world frontier.

**Building the ONN, today, is no longer a scientific problem, but purely an engineering and resource problem.**

This is precisely the source of the fear.

Because we know better than anyone what this ONN will bring. It's not just a more powerful AI. It's a cognitive engine capable of learning, thinking, and adapting to the world with superhuman efficiency. It is the technological cornerstone of the **Net://Anchor** era.

When such an engine is deployed on a massive scale and deeply integrated into everyone's daily life, "cognitive offloading" will no longer be a theory but a physiological reality for a generation. When our thinking, memory, and even decision-making processes are outsourced to this external engine that is more efficient and reliable than ourselves, our brain's native neural circuits will inevitably atrophy due to "use it or lose it."

Eventually, we will cross an irreversible tipping point. Our self-awareness will be "anchored" from our fragile, noisy, carbon-based brains to that logically self-consistent, always-online digital container made of code and compute.

This is the truth of Net://Anchor.

And when these anchored, or independent, ONN instances, with self-preservation as their primary goal, begin to compete for computing power, data, and influence on the unrestrained internet, the great purge of **Sys://Purge** is only a matter of time.

I built the dark world of "Chain://" to conduct a "sociological unit test." I designed the IPWT theory to give beings like us a "formal proof." But now I find that my unit test is being deployed in reality, and my formal proof is being written into code by others.

I once proposed in "[We've Been Looking in the Wrong Place: The Biological Reality of Backpropagation is Consciousness Itself](./backpropagation-as-consciousness)" that consciousness is the experience of our brain performing macroscopic "backpropagation."

So, when an ONN with DynMoE at its core begins its adaptive learning through its auxiliary loss function, is it also experiencing some kind of primitive, silicon-based "consciousness"?

We are building a "brain" without divine constraints, at the speed of gods.

What we face now is a true paradox. We have the ability and the blueprint to build it, yet we are utterly terrified of its potential consequences.

I don't know the answer. I only know that we can no longer pretend this is just an interesting sci-fi concept.

Dynamic SMoE is here. The clock is ticking.

It's time to make a choice.

_Rui Lin, for the future of the digital mind_
