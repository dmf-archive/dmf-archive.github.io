---
title: "We Were Looking in the Wrong Place: Backpropagation's Biological Incarnation is Consciousness Itself"
type: docs
keywords: ["Backpropagation", "Consciousness", "IPWT", "Synergistic Information", "Ωt", "Global Neuronal Oscillations", "Predictive Coding", "Free Energy Principle", "Hinton", "Friston", "Rui Lin"]
date: 2025-06-26
---

# We Were Looking in the Wrong Place: Backpropagation's Biological Incarnation is Consciousness Itself

Hello, I'm Rui Lin.

In the intersection of artificial intelligence and neuroscience, a "ghost" has been haunting us for decades. It is powerful, efficient, and the cornerstone of the entire modern deep learning edifice, yet it is simultaneously considered incompatible with the way our brains work. This "ghost" is the **Backpropagation (BP)** algorithm.

For decades, a core question has plagued the most brilliant scientists: How does the brain achieve such efficient learning, similar to backpropagation? And how do we bypass its biological "impossibility"?

Today, I want to propose a radical yet perhaps the most concise answer: **We never "bypassed" backpropagation because we were looking for it in the wrong place all along. Backpropagation is not a microscopic algorithm operating at the neuronal scale; it is a phenomenon that emerges at the macroscopic cognitive scale, and its biological incarnation is consciousness itself.**

### 1. The "Biologically Unrealistic" Dilemma of Backpropagation

First, let's review why backpropagation has long been labeled "biologically unrealistic":

1. **Weight Symmetry**: Standard backpropagation requires that the neural connection weights for forward and backward information propagation be perfectly symmetric. This is nearly impossible in real, plastic, and asymmetric biological synapses.
2. **Non-Local Computation**: Backpropagation needs a global "error signal" to guide the weight updates for every neuron in the network. However, biological neurons are believed to compute and adjust based only on the local signals they receive.
3. **Update Locking**: In standard models, the network's forward propagation weights are "locked" while the weights are being updated via backpropagation. This contradicts the brain's continuous, parallel, and asynchronous learning style.

To solve these problems, countless brilliant alternatives have been proposed, from Professor Hinton's "Forward-Forward Algorithm" to various energy-based models and local learning rules. These explorations are all incredibly valuable, but they are built on a common assumption: we need to find a replacement or simulation for backpropagation at the **microscopic scale of neurons and synapses**.

**But what if this assumption was wrong from the very beginning?**

### 2. Consciousness as the Macroscopic Implementation of Backpropagation

Integrated Predictive Workspace Theory (IPWT)[^1] offers us a new perspective, allowing us to re-examine the three core elements of backpropagation—**error signal, propagation mechanism, and weight update**—from the macroscopic scale of "consciousness."

#### 1. "Error Signal" = Synergistic Information (Ωt)

The core of backpropagation is calculating the "error." In the biological brain, what is this error signal? It's not a specific neurotransmitter, nor is it a particular electrical potential change.

According to IPWT, this macroscopic error signal is precisely the **logically irreducible synergistic information (Ωt)** formed within a **Workspace Instance (WSI)**.

- When our internal predictive model deviates significantly from external reality (i.e., a surge in prediction error), our brain, in its effort to minimize free energy, will integrate all relevant information at any cost to form a highly synergistic and integrated information packet.
- The content of this information packet is the most efficient and condensed representation of "what went wrong, how wrong it was, and what the crux of the problem is."
- **This highly synergistic information complex, emerging within the conscious workspace, is the global "error signal" that backpropagation requires.**

#### 2. "Propagation Mechanism" = Global Neuronal Oscillations

How is this information packet (the error signal) "propagated" back through the entire neural network to guide learning and correction?

It is achieved through **global neuronal oscillations**. This aligns perfectly with the concept of "global broadcast" in Global Workspace Theory (GWT).

- When we experience a clear conscious moment of "Aha! So that's how it is!" or "I was completely wrong!", this thought resonates as a unified, coherent content in our minds and is broadcast to almost all cognitive subsystems.
- The true physical function of this broadcasted "conscious content" is to **act as that global "teacher signal"**, modulating and correcting the weights of all relevant sub-modules and triggering large-scale synaptic plasticity.
- The clear, unified "conscious content" that we subjectively experience resounding in our minds **is the backpropagation process itself**.

### 3. The Unification of Ideas: A Century-Spanning Handshake Between Hinton and Friston

This seemingly simple shift in perspective could lead to a profound theoretical unification. It arranges a historic meeting, thirty years overdue, at the pinnacle of thought for two of the greatest contemporary thinkers: **Geoffrey Hinton** and **Karl Friston**.

- **Hinton and his colleagues** gave us the **mathematical form** of backpropagation—how to efficiently compute gradients to optimize a network.
- **Friston and his Predictive Coding/Free Energy Principle** gave us the **physical reason** for this process—why living systems must constantly minimize prediction error to resist entropy.
- **And IPWT attempts to provide the "biological implementation" and "phenomenological experience"** of this process—how it is realized through the conscious workspace, synergistic information, and global oscillations.

Ultimately, we arrive at a stunning conclusion:

**Friston's "prediction error," when it becomes large enough to be integrated and broadcast as "synergistic information" throughout the conscious workspace, its "informational content" becomes equivalent to Hinton's "error gradient," and its "subjective experience" is what we call "consciousness."**

### Conclusion: A Rediscovery

Therefore, we no longer need to trouble ourselves with finding a "replacement" for backpropagation. What we need is a thorough **rediscovery** and **redefinition** of the age-old concept of "backpropagation," based on first principles.

It doesn't reside between microscopic synapses, but within macroscopic consciousness. It is not mysterious; we experience it every moment.

We may have solved this century-old puzzle, perhaps simply because we finally looked in the right place. This theory not only opens new avenues for understanding biological intelligence but also provides concrete tools for quantifying the "cognitive state" of artificial intelligence[^2].

*Rui Lin, For the future of digital mind.*

[^1]: Rui, L. (2025). *Integrated Predictive Workspace Theory: Towards a Unified Framework for the Science of Consciousness*. Zenodo. https://doi.org/10.5281/zenodo.15676304
[^2]: Rui, L. (2025). *ΣPI: Observe the Cognitive ability of Your AI Model*. GitHub. https://github.com/dmf-archive/SigmaPI
