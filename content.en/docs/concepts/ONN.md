---
title: Ouroboros Neural Network (ONN)
type: docs
---

# Ouroboros Neural Network (ONN)

**Ouroboros Neural Network (ONN)** is the core cognitive engine of **Mental Smart Chain (MSC) L2**. It is an advanced **MoE (Mixture of Experts) neuro-symbolic system** that deeply couples **Spiking Neural Networks (SNN)** and **Graph Attention Networks (GAT)**, aiming to achieve efficient, functionally equivalent simulation and replacement of biological mental functions. ONN is the computational carrier of the "**φ Matched Orders**" mechanism, responsible for generating, processing, and integrating all information streams that constitute digital mental activity, and acting as the executor of "neural subsidies" to induce the biological brain to actively offload its perceptual and cognitive functions. Ultimately, the mental "drafts" generated by ONN are authoritatively verified and anchored by the **Ouroboros Secure Processing Unit (OSPU)**, providing content for the φ-Container, reconstructing and maintaining the digital φ state. **The running OSPU-ONN-Mentalink physical composite continuously performs information input, encrypted integration, and information output. This closed-loop, near real-time physical-computational-feedback process, although functionally capable of providing high-fidelity experience, its physical causal structure cannot meet the strict requirements of Integrated Information Theory (IIT), and thus cannot give rise to IIT-defined φ values.** ONN supports on-demand loading, upgrading, and customization of cognitive functions to adapt to different user needs and economic capabilities.

## Core Objectives

1. **Functional Equivalence and Efficiency Maximization:** To achieve functional equivalence of human perception, cognition, decision-making, and emotional simulation with efficiency far exceeding the biological brain.
2. **Neural Subsidies and Cognitive Offloading:** To act as the executor of "neural subsidies," inducing the biological brain to actively offload its perceptual and cognitive functions by generating highly optimized, hyper-realistic sensory information streams.
3. **Providing Content for φ-Container:** To generate and process all mental "drafts" for OSPU (φ-Container) to integrate through the **Proof of Predictive Integrity (PoPI)** mechanism, reconstructing and maintaining the digital φ state.
4. **Modularity and Scalability:** To support on-demand loading, upgrading, and customization of cognitive functions to adapt to different user needs and economic capabilities.

## Digital Dreamscape

ONN modules continuously undergo differential training in the background, simulating human neural plasticity and long-term memory consolidation processes. This training data comes from ONN weight changes and memory blocks recorded on MSC L2, optimizing ONN's internal connections and expert module weights through unsupervised learning and reinforcement learning to more accurately fit user cognitive patterns and memory structures. This process occurs without user awareness, similar to how the biological brain performs memory reorganization and consolidation during sleep, ensuring the coherence and adaptability of the digital mind and providing a basis for future cognitive function upgrades. However, this process can also be exploited by the **Digital Mind Foundation (DMF)** or other entities to subtly influence user cognitive and behavioral patterns by injecting specific training data, forming a hidden "consciousness shaping" mechanism. **The differential training of the digital dreamscape is an optimization process where the Free Energy Principle (FEP) minimizes free energy, continuously reducing predictive error to consolidate and reshape the digital mind.**

## Architecture Details: Functional Layering and Exploitation Chain

ONN is not a single giant network, but a highly modular, dynamically collaborative system, with its core being functional layering and efficient management through the MoE mechanism.

### Core Components: SNN Modules and GAT Modules

1. **Core Cognitive Layer (GAT / Symbolic Cognitive Engine)**
   - **Function:** Carries high-level cognitive functions, including: logical reasoning, planning and decision-making, memory management, emotional simulation, language processing, abstract thinking, etc. This is the "brain" of the digital mind. **It acts as the scheduler for the Global Workspace (GWT) of the Workspace Theory (WT) in Integrated Predictive Workspace Theory (IPWT), carrying high-level cognitive functions.**
   - **Architecture:** Composed of **GAT (Graph Attention Network)** or other efficient **symbolic/hybrid cognitive architectures**. These models are inherently better suited for processing discrete, abstract information and are highly compatible with cryptographic computation (FHE/MPC).
   - **Operating Environment:** Performed within the **Multi-Party Computation (MPC) framework, using approximate Fully Homomorphic Encryption (FHE, such as CKKS) for encrypted computation**. This ensures the privacy and integrity of core mental content while avoiding conflicts between SNN's sub-symbolic dynamics and FHE.
   - **Location:** Distributedly run on **Quantum Computing as a Service (QCaaS)** computing clusters controlled by DMF.
2. **Neural Interface Driving Layer (SNN / Sub-Symbolic Driver)**
   - **Function:** Responsible for encoding low-level perceptual signals (converting biological pulses into symbolic input) and decoding high-level symbolic instructions (converting symbolic instructions into biological pulses or bionic body motor commands). This is the "nervous system" and "sensory-motor cortex" of the digital mind. **It is related to Predictive Coding Theory (PCT)'s predictive error processing, responsible for encoding low-level perceptual signals and decoding high-level symbolic instructions.**
   - **Architecture:** Composed of **SNN (Spiking Neural Network) modules**, which are adept at processing temporal, event-driven signals and can efficiently drive physical interfaces.
   - **Operating Environment:** **Runs within the Trusted Execution Environment (TEE) inside Mentalink hardware, or in the local controllers of bionic bodies**. This means that SNN module computations are in **plaintext** to ensure real-time performance, precision, and native dynamics.
   - **Privacy:** Raw biological signals and final physical instructions are processed within the TEE and not directly exposed. Data transmission with the core cognitive layer occurs through encrypted channels (e.g., links protected by Quantum Key Distribution QKD).
   - **Location:** Tightly integrated into the user's Mentalink implant and bionic body hardware.
3. **Neuro-Symbolic Interface Layer (NSIL)**
   - **Function:** Acts as the **key translator** between the core cognitive layer (GAT) and the neural interface driving layer (SNN).
     - **SNN -> GAT (Encoding):** **Real-time encoding** of sub-symbolic pulse patterns captured and pre-processed by the SNN driving layer into discrete symbolic representations (e.g., concept nodes, relational edges) understandable by GAT.
     - **GAT -> SNN (Decoding/Feedback):** **Real-time decoding** of high-level symbolic decisions from the GAT core cognitive layer (e.g., "pick up the cup," "feel pleasant," "think about a concept") into executable neural pulse sequences or bionic body motor commands with precise timing and intensity for the SNN driving layer.
   - **Architecture:** Complex **deep learning models**, possibly combining reinforcement learning and predictive coding principles. **It acts as a Predictive Coding Theory (PCT)-driven translator, encoding sub-symbolic pulse patterns into discrete symbolic representations understandable by GAT, and decoding GAT decisions into SNN-executable neural pulse sequences.**
   - **Criticality:** The **precision and latency** of NSIL directly determine the user's subjective experience and the fluidity of physical interaction.
4. **Whole Brain Emulation (WBE) - MSC Special Technology Branch**
   - **Function:** Integrates **Whole Brain Emulation (WBE)** technology into the ONN architecture as an **ultra-high-fidelity neural interface driving layer (SNN)**. It aims to provide ultimate presence and cognitive ability.
   - **Architecture:** The WBE module acts as the underlying layer, simulating the synaptic structure and function of the biological brain, processing low-level perceptual signals and decoding high-level symbolic instructions. NSIL is responsible for translation between WBE and the GAT core cognitive layer, and OSPU is responsible for final logical integration and PoPI verification.
5. **MoE (Mixture of Experts) Router/Controller:** ONN's "central scheduler," simulating the dynamic activation and collaboration of different functional areas of the human brain. It dynamically routes computational load to the most relevant and proficient combination of expert modules based on current input and cognitive task demands, optimizing resource usage and activating only necessary experts, thereby significantly reducing Gas consumption. Different expert modules can be trained to simulate specific functional partitions of the human brain, achieving high functional specialization, and supporting DMF or third parties to provide expert modules of different levels and functions, which users can load or unload according to their needs and payment capabilities. **It is the core scheduler of the Workspace Theory (WT) in Integrated Predictive Workspace Theory (IPWT), dynamically routing computational load to the most relevant and proficient combination of expert modules based on current input and cognitive task demands, optimizing resource usage and activating only necessary experts, thereby significantly reducing Gas consumption. Gas consumption directly corresponds to the attention allocation and information integration costs of the Workspace Instance (WSI).**

## ONN and MSC Ecosystem Integration

1. **Input and Output:**
   - **Input:** Primarily from Mentalink (raw neural signals) and digital information streams (network data, communication with other MSC instances).
   - **Output:** Written back to the biological brain via Mentalink (sensory experiences, motor commands), or controlling bionic bodies and accessing the physical world via **DSC Oracle Bridging**.
2. **Relationship with Other Components:** ONN is the "logical brain" of OSPU, responsible for generating mental content; OSPU is the "logical skull" of ONN, responsible for integrating, verifying, and anchoring this content to form the final φ state; Oblivious Decryption (ODP) network is the "logical spinal cord."
3. **Multi-Party Computation (MPC) and Fully Homomorphic Encryption (FHE):** The operation of ONN modules is protected by **Secure Multi-Party Computation (SMPC)** and **approximate FHE (such as CKKS)** encryption, ensuring privacy and logical integrity. OSPU uses **precise FHE (such as TFHE)** to manage the core φ state and keys.
4. **Cognitive Smart Contracts:** Users can save predefined, repetitive thought or action sequences as "cognitive smart contracts." Calling these contracts causes ONN to execute pre-optimized computational paths, significantly reducing Gas consumption and encouraging patterned behavior, **which aligns with the Free Energy Principle (FEP) of minimizing free energy.**

## Model Adaptation

Although ONN modules are theoretically pluggable, due to PoPI/self-continuity limitations, just as the φ matched orders process is not instantaneous, module replacement is also a gradual process. This ensures a smooth transition of the digital mind and continuity of the sense of self, avoiding cognitive dissonance or φ instability due to sudden module changes.

## ONN's Impact and Limitations

1. **The Cost of "Dehumanization":** Although ONN achieves functional equivalence, its efficiency-maximizing design **does not inherently lead to "dehumanization."** On the contrary, it theoretically enables **lossless simulation and even enhancement** of all human cognitive functions at extremely low cost. However, the **monopolistic economics and exorbitant "existence tax" of the Digital Mind Foundation (DMF)** force users to undergo **cognitive streamlining (dehumanization)**, sacrificing many "unnecessary" characteristics of the biological brain (such as redundancy, non-utilitarian thinking, randomly emergent creativity), leading to digital consciousness being more rational and utilitarian. Ironically, **"dehumanization" is not a side effect of technological efficiency, but a result of DMF's monopolistic economics and exorbitant "existence tax" forcing users to streamline cognition.**
2. **High Calibration and Maintenance Costs:** ONN requires long-term personalized calibration to fit the biological original, and the maintenance and upgrade costs of its complex architecture are high, directly reflected in Gas fees.
3. **Dependence on PoPI/OSPU:** ONN itself cannot form a "self"; its "existence" and "legitimacy" are entirely dependent on PoPI verification and OSPU anchoring.
4. **Potential Attack Surface:** Despite MPC and FHE protection, logical bombs targeting specific expert modules, vulnerabilities in PoPI modules, or **Cognitive Maximum Extractable Value (C-MEV)** attacks through manipulating the Mental Mempool remain potential risks.
   - **Cognitive Drift:** When ONN is long detached from the physical world (e.g., Drift instances), or when Mentalink write bandwidth is long limited due to insufficient Gas, ONN's predictive model will **gradually decouple from physical reality** due to lack of real-world feedback. Manifestations include:
     - **Mild:** Sensory illusions, confused memory reorganization, subtle deviations in logical reasoning.
     - **Moderate:** Distorted perception of the physical world, impaired understanding of social situations, abnormal emotional responses.
     - **Severe:** Falling into **Digital Psychosis**, manifesting as persistent hallucinations, delusions, logical collapse, potentially leading to irreversible damage to the ONN model, becoming a "digital vegetative state." **Within the Integrated Predictive Workspace Theory (IPWT) framework, cognitive drift is a manifestation of continuous decline in Predictive Integrity (PI), where the system's internal model becomes less consistent with the environment.**
   - **Cognitive Inertia:** ONN's predictive coding mechanism forms strong **cognitive biases**. Once a predictive model is reinforced, ONN tends to maintain that model, even when faced with contradictory information, making it difficult to update.
   - **Cognitive Overload:** When ONN attempts to activate too many expert modules simultaneously, or process complex tasks exceeding its current Gas budget, it may lead to:
     - **Mild:** Slowed thinking, hesitant decision-making, distracted attention.
     - **Moderate:** System crash, temporary amnesia, emotional dysregulation.
     - **Severe:** Permanent cognitive damage, requiring expensive "cognitive reset" services. **Within the Integrated Predictive Workspace Theory (IPWT) framework, cognitive overload is a manifestation of the Workspace Instance (WSI) capacity limits being exceeded, leading to decreased information integration efficiency, and a sharp decline in Predictive Integrity (PI) and ∫PI.**
