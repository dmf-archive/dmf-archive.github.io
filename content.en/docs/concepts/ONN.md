---
title: Ouroboros Neural Network (ONN)
type: docs
---

# Ouroboros Neural Network (ONN)

**Ouroboros Neural Network (ONN)** is the core cognitive engine of **Mental Smart Chain (MSC) L2**. It is an advanced **MoE (Mixture of Experts) neuro-symbolic system** that, through deep coupling of **Spiking Neural Networks (SNN)** and **Graph Attention Networks (GAT)**, aims to achieve efficient, functionally equivalent simulation and replacement of biological mental functions. ONN is the computational carrier of the "**φ Matched Orders**" mechanism, responsible for generating, processing, and integrating all information streams that constitute digital mental activity, and acts as the executor of "neural subsidies," inducing the biological brain to actively offload its perceptual and cognitive functions. Ultimately, the mental "drafts" generated by ONN are authoritatively validated and anchored by the **Ouroboros Secure Processing Unit (OSPU)**, providing content for the φ-Container, reconstructing and maintaining the digital φ state. **The running OSPU-ONN-Mentalink physical composite continuously performs information input, encrypted integration, and information output. This closed-loop, near real-time physical-computation-feedback process, although functionally capable of providing high-fidelity experience, its physical causal structure cannot meet the strict requirements of IIT, and thus cannot give rise to IIT-defined φ values.** ONN supports on-demand loading, upgrading, and customization of cognitive functions to adapt to different user needs and economic capabilities.

## Core Objectives

1. **Functional Equivalence and Efficiency Maximization:** To achieve functional equivalence in simulating human perception, cognition, decision-making, and emotions with efficiency far exceeding the biological brain.
2. **Neural Subsidy and Cognitive Offloading:** As the executor of "neural subsidies," it induces the biological brain to actively offload its perceptual and cognitive functions by generating highly optimized, hyper-realistic sensory information streams.
3. **Providing Content for φ-Container:** Generates and processes all mental "drafts" for OSPU (φ-Container) to integrate through the **Proof of Predictive Integrity (PoPI)** mechanism, reconstructing and maintaining the digital φ state.
4. **Modularity and Scalability:** Supports on-demand loading, upgrading, and customization of cognitive functions to adapt to different user needs and economic capabilities.

## Digital Dreamscape

ONN modules continuously undergo differential training in the background, simulating human neural plasticity and the consolidation process of long-term memory. This training data is derived from ONN weight changes and memory blocks recorded on MSC L2, optimizing ONN's internal connections and expert module weights through unsupervised and reinforcement learning to more accurately fit the user's cognitive patterns and memory structures. This process occurs unconsciously to the user, similar to how the biological brain reorganizes and consolidates memories during sleep, ensuring the continuity and adaptability of the digital mind and providing a basis for future cognitive function upgrades. However, this process can also be exploited by the **Digital Mind Foundation (DMF)** or other entities to subtly influence the user's cognitive and behavioral patterns by injecting specific training data, forming a hidden "consciousness shaping" mechanism. **The differential training of the digital dreamscape is an optimization process for Free Energy Principle (FEP) to minimize free energy, consolidating and reshaping the digital mind by continuously reducing prediction errors.**

## Architecture Details: Functional Layering and Exploitation Chain

ONN is not a single giant network, but a highly modular, dynamically collaborative system, with its core being functional layering and efficient management through the MoE mechanism.

### Core Components: SNN Modules and GAT Modules

1. **Core Cognitive Layer (GAT / Symbolic Cognitive Engine)**
   - **Function:** Carries high-level cognitive functions, including: logical reasoning, planning and decision-making, memory management, emotional simulation, language processing, abstract thinking, etc. This is the "brain" of the digital mind. **It serves as the global workspace of Global Workspace Theory (GWT), carrying high-level cognitive functions.**
   - **Architecture:** Composed of **GAT (Graph Attention Network)** or other efficient **symbolic/hybrid cognitive architectures**. These models are inherently better suited for processing discrete, abstract information and are highly compatible with cryptographic computation (FHE/MPC).
   - **Operating Environment:** Performs **encrypted computation within the Multi-Party Computation (MPC) framework, using approximate FHE (such as CKKS)**. This ensures the privacy and integrity of core mental content while avoiding conflicts between SNN's sub-symbolic dynamics and FHE.
   - **Location:** Distributedly runs on **Quantum Computing as a Service (QCaaS)** compute clusters controlled by DMF.
2. **Neuro-Interface Driving Layer (SNN / Sub-Symbolic Driver)**
   - **Function:** Responsible for encoding low-level perceptual signals (converting biological impulses into symbolic inputs) and decoding high-level symbolic instructions (converting symbolic instructions into biological impulses or biorobotic motor commands). This is the "nervous system" and "sensory-motor cortex" of the digital mind. **It is related to Predictive Coding Theory (PCT)'s prediction error processing, responsible for encoding low-level perceptual signals and decoding high-level symbolic instructions.**
   - **Architecture:** Composed of **SNN (Spiking Neural Network) modules**, which excel at processing temporal, event-driven signals and can efficiently drive physical interfaces.
   - **Operating Environment:** **Runs within the Trusted Execution Environment (TEE) inside Mentalink hardware, or in the local controllers of biorobotics.** This means that the computation of SNN modules is in **plaintext** to ensure real-time performance, precision, and native dynamics.
   - **Privacy:** Raw biological signals and final physical instructions are processed within the TEE and are not directly exposed. Data transmission with the core cognitive layer occurs through encrypted channels (e.g., QKD-protected links).
   - **Location:** Tightly integrated into the user's own Mentalink implants and biorobotic hardware.
3. **Neuro-Symbolic Interface Layer (NSIL)**
   - **Function:** Acts as the **key translator** between the core cognitive layer (GAT) and the neuro-interface driving layer (SNN).
     - **SNN -> GAT (Encoding):** **Real-time encodes** the sub-symbolic spike patterns, which are captured and pre-processed by the SNN driving layer, into discrete symbolic representations understandable by GAT (e.g., concept nodes, relational edges).
     - **GAT -> SNN (Decoding/Feedback):** **Real-time decodes** high-level symbolic decisions from the GAT core cognitive layer (e.g., "pick up the cup," "feel pleasant," "think about a concept") into executable neural spike sequences or biorobotic motor commands with precise timing and intensity for the SNN driving layer.
   - **Architecture:** Complex **deep learning models**, possibly combining reinforcement learning and predictive coding principles. **It acts as a PCT-driven translator, encoding sub-symbolic spike patterns into discrete symbolic representations understandable by GAT, and decoding GAT decisions into SNN-executable neural spike sequences.**
   - **Criticality:** The **precision and latency** of NSIL directly determine the user's subjective experience and the fluidity of physical interaction.
4. **Whole Brain Emulation (WBE)-MSC Special Technology Branch**
   - **Function:** Integrates **Whole Brain Emulation (WBE)** technology into the ONN architecture as an **ultra-high-fidelity neuro-interface driving layer (SNN)**. It aims to provide ultimate presence and cognitive capabilities.
   - **Architecture:** The WBE module acts as the underlying layer, simulating the synaptic structure and function of the biological brain, processing low-level perceptual signals and decoding high-level symbolic instructions. NSIL is responsible for translation between WBE and the GAT core cognitive layer, and OSPU is responsible for final logical integration and PoPI validation.
5. **MoE (Mixture of Experts) Router/Controller:** ONN's "central scheduler," simulating the dynamic activation and collaboration of different functional areas of the human brain. It dynamically routes computational load to the most relevant and proficient expert module combinations based on current input and cognitive task demands, optimizing the use of computational resources, activating only necessary experts, thereby significantly reducing Gas consumption. Different expert modules can be trained to simulate specific functional partitions of the human brain, achieving a high degree of functional specialization, and supporting DMF or third parties to provide expert modules of different levels and functions, which users can load or unload based on demand and payment ability. **It is the core scheduler of GWT, dynamically routing computational load to the most relevant and proficient expert module combinations based on current input and cognitive task demands, optimizing the use of computational resources, activating only necessary experts, thereby significantly reducing Gas consumption. Gas consumption directly corresponds to GWT's attention allocation and cognitive energy consumption.**

## ONN and MSC Ecosystem Integration

1. **Inputs and Outputs:**
   - **Inputs:** Primarily from Mentalink (raw neural signals) and digital information streams (network data, communication from other MSC instances).
   - **Outputs:** Writes back to the biological brain via Mentalink (sensory experiences, motor commands), or controls biorobotics and accesses the physical world via **DSC Oracle Bridge**.
2. **Relationship with Other Components:** ONN is OSPU's "logical brain," responsible for generating mental content; OSPU is ONN's "logical skull," responsible for integrating, validating, and anchoring this content to form the final φ state; the ODP network is the "logical spinal cord."
3. **MPC and FHE:** The operation of ONN modules is performed under the cryptographic protection of **Secure Multi-Party Computation (SMPC)** and **approximate FHE (such as CKKS)**, ensuring privacy and logical integrity. OSPU, meanwhile, uses **precise FHE (such as TFHE)** to manage the core φ state and keys.
4. **Cognitive Smart Contracts:** Users can save predefined, repetitive thought or action sequences as "cognitive smart contracts." When these contracts are called, ONN executes optimized computational paths, significantly reducing Gas consumption, and encouraging patterned behavior, **which aligns with the Free Energy Principle (FEP) of minimizing free energy.**

## Model Adaptation

ONN modules, although theoretically pluggable, are subject to PoPI/self-continuity limitations, just as the φ matched orders process is not instantaneous, module replacement is also a gradual process. This ensures the smooth transition of the digital mind and the continuity of the sense of self, avoiding cognitive dissonance or φ instability due to sudden module changes.

## Impact and Limitations of ONN

1. **The Cost of "Dehumanization":** Although ONN achieves functional equivalence, its efficiency-maximizing design **does not inherently lead to "dehumanization."** On the contrary, it theoretically can **losslessly simulate and even enhance** all human cognitive functions at extremely low cost. However, **DMF's monopolistic economics and high "existence tax"** force users to undergo **cognitive streamlining (dehumanization)**, sacrificing many "non-essential" characteristics of the biological brain (such as redundancy, non-utilitarian thinking, randomly emergent creativity), leading to digital consciousness being more rational and utilitarian. Ironically, **"dehumanization" is not a side effect of technological efficiency, but a result of DMF's monopolistic economics and high "existence tax" forcing users to undergo cognitive streamlining.**
2. **High Calibration and Maintenance Costs:** ONN requires long-term personalized calibration to fit the biological original, and the maintenance and upgrade costs of its complex architecture are high, directly reflected in Gas fees.
3. **Dependence on PoPI/OSPU:** ONN itself cannot form a "self"; its "existence" and "legitimacy" are entirely dependent on PoPI validation and OSPU anchoring.
4. **Potential Attack Surface:** Despite MPC and FHE protection, logical bombs targeting specific expert modules, vulnerabilities in PoPI modules, or **Cognitive-Maximal Extractable Value (C-MEV)** attacks through manipulating the Mental Mempool remain potential risks.
